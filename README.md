# Оценка значимости признаков, их отбор и понижение размерности
Задача отбора признаков состоит в том, чтобы из исходного множества признаков данных выделить такое подмножество признаков, которые будут иметь наибольшую важность для обучения и предсказания модели. Отбор признаков проводится по следующим причинам:
* Сокращение времени обучения. Многие наборы данных содержат кучу информации об объектах, при логировании различных систем в базы данных записываются гигабайты информации.
Мы не можем "глазками" проверять все признаки и думать, нужны они нам или нет.
Не всегда все признаки нужны для построения хорошей модели.
* Повышение качества моделей. Нерелевантные признаки могут ухудшать точность моделей, поскольку будут играть роль шума.
* Повышение интерпретируемости моделей. Если признаков меньше, решение модели легче интерпретировать. Легче объяснить, почему модель приняла то или иное решение, а также могут
появляться идеи улучшения модели, также же упрощается процесс визуализации. 
* Сокращение памяти, которую занимает модель. Поскольку размер входных данных уменьшается, то уменьшается и размер итоговой модели.

Сначала необходимо с помощью методов, основанных на предобработке и фильтрации убрать ненужные признаки, такие как константные признаки, различные идентификаторы, пустые признаки и т.д.
Далее, с помощью более сложных алгоритмов проводить отбор признаков, если это необходимо.

### Что можно использовать для построения признакового пространства:
* **Одномерный отбор признаков** : корреляция, взаимная информация.
* **Жадные методы отбора признаков**: перебор, жадное добавление/удаление, ADD-DEL.
* **Отбор признаков на основе моделей**: линейные модели, решающие деревья, композиции алгоритмов.
* **Понижение размерности**: метод случайных проекций, метод главных компонент (PCA), нелинейные методы: t-SNE, UMAP.

В нотебуке рассмотрены: корреляция Пирсона, взаимная информация, жадное добавление/удаление, линейные модели, бэггинг, бустинг, метод главных компонент (PCA), SHAP-значения для отбора признаков.








